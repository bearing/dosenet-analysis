{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import glob\n",
    "import datetime\n",
    "from itertools import accumulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Richie Woo, Dosenet Intern 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RICHIE PAIR or FILE IS PURPLE AIR DON'T FORGET\n",
    "\n",
    "def main():\n",
    "    os.chdir('sensor-data')\n",
    "            \n",
    "    folder_lists = os.listdir()\n",
    "    print(folder_lists)\n",
    "    \n",
    "    for folder in folder_lists:\n",
    "        print(\"\")\n",
    "        print(\"---------------\")\n",
    "        print(folder)\n",
    "        dosenet_data = get_url(folder)\n",
    "        dosenet_data = dosenet_data.sort_values('deviceTime_utc')\n",
    "        \n",
    "        os.chdir(folder)\n",
    "        pair_file_list = glob.glob('*.csv')\n",
    "        print('found ', len(pair_file_list), ' files')\n",
    "        n = 0\n",
    "        for file in pair_file_list:\n",
    "            directory = os.getcwd()\n",
    "            n += 1\n",
    "            print('file ', n, ':')\n",
    "            file_data = pd.read_csv(file)\n",
    "            dosenet_data = get_url(folder)\n",
    "            dosenet_data = dosenet_data.sort_values('deviceTime_utc')\n",
    "            \n",
    "            all_data = fix_data(dosenet_data, file_data)\n",
    "            pm = '1'\n",
    "            diffstring = str('pm' + pm + 'diff')\n",
    "            difference_data = compare_data(all_data, pm)\n",
    "            all_data.loc[:, diffstring] = difference_data\n",
    "            pm = '25'\n",
    "            diffstring = str('pm' + pm + 'diff')\n",
    "            difference_data = compare_data(all_data, pm)\n",
    "            all_data.loc[:, diffstring] = difference_data\n",
    "            pm = '10'\n",
    "            diffstring = str('pm' + pm + 'diff')\n",
    "            difference_data = compare_data(all_data, pm)\n",
    "            all_data.loc[:, diffstring] = difference_data\n",
    "            \n",
    "            #stupid windows uses \\ instead of /. Edit the code to save the files to a different location if you want.\n",
    "            filestring = str(str(folder) + '_' + str(n) + '_daily' + '.csv')\n",
    "            print('saving as:', str(filestring))\n",
    "            \n",
    "            os.chdir(r'C:\\Users\\Richie Woo\\Documents\\python-scripts\\processed_data\\daily\\abs')\n",
    "            all_data.to_csv(filestring, index = False)\n",
    "            os.chdir(directory)\n",
    "            \n",
    "        os.chdir(os.path.dirname(os.getcwd()))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data(dosenet_data, file_data):\n",
    "    #drop unncessary columns\n",
    "    dosenet_data = dosenet_data.drop(['deviceTime_local', 'deviceTime_utc', 'error_flag'], axis=1)\n",
    "    file_data = file_data.drop(['Humidity_%', 'UptimeMinutes', 'Temperature_F', 'RSSI_dbm', 'entry_id', 'PM2.5_CF1_ug/m3'], axis=1)\n",
    "    \n",
    "    #preparation for data.\n",
    "    #below for dosenet\n",
    "    dosenet_data = dosenet_data.sort_values('deviceTime_unix')\n",
    "    dosenet_data = dosenet_data.iloc[::-1]\n",
    "    dosenet_data = dosenet_data.reset_index(drop=True)\n",
    "    d_unix_list = dosenet_data['deviceTime_unix']\n",
    "    \n",
    "    #below for pair\n",
    "    file_data = file_data.sort_values('created_at')\n",
    "    file_data = file_data.iloc[::-1]\n",
    "    file_data = file_data.reset_index(drop=True)\n",
    "    f_temp_uptime = file_data['created_at']\n",
    "    f_unix_list = []\n",
    "    f_unix_list = [string.replace(' UTC', '') for string in f_temp_uptime]\n",
    "    f_unix_list = [int(datetime.datetime.strptime(time, '%Y-%m-%d %H:%M:%S').replace(tzinfo=datetime.timezone.utc).timestamp()) for time in f_unix_list]\n",
    "    file_data['Unix_time'] = f_unix_list\n",
    "    file_data = file_data.drop(['created_at', 'Unnamed: 10'], axis=1)\n",
    "    \n",
    "    #merge stuff here\n",
    "    fmin, fmax = compare_length(d_unix_list, f_unix_list)\n",
    "    d_unix_list = [x for x in d_unix_list if x <= fmax and x >= fmin]\n",
    "    f_unix_list = [x for x in f_unix_list if x <= fmax and x >= fmin]\n",
    "\n",
    "    #cuts out data indices we don't want\n",
    "    dosenet_data = dosenet_data[dosenet_data['deviceTime_unix'].isin(d_unix_list)]\n",
    "    file_data = file_data[file_data['Unix_time'].isin(f_unix_list)]\n",
    "    \n",
    "    \n",
    "    #reset Indices\n",
    "    dosenet_data = dosenet_data.reset_index(drop=True)\n",
    "    file_data = file_data.reset_index(drop=True)\n",
    "    \n",
    "    #rename columns\n",
    "    dosenet_data.rename(columns = {'deviceTime_unix':'date_time'}, inplace = True)\n",
    "    file_data.rename(columns = {'Unix_time':'date_time'}, inplace = True)\n",
    "    \n",
    "    #converts unix to date, time\n",
    "    file_data['date_time'] = pd.to_datetime(file_data['date_time'],unit='s')\n",
    "    dosenet_data['date_time'] = pd.to_datetime(dosenet_data['date_time'],unit='s')\n",
    "    \n",
    "    #finds mean per hour\n",
    "    dosenet_data = dosenet_data.resample('d', on='date_time')['PM1', 'PM25', 'PM10'].mean().reset_index()\n",
    "    file_data = file_data.resample('d', on='date_time')['PM1.0_CF1_ug/m3', 'PM10.0_CF1_ug/m3', 'PM2.5_ATM_ug/m3'].mean().reset_index()\n",
    "\n",
    "    #creates a combined dataframe\n",
    "    all_data = pd.merge(dosenet_data, file_data)\n",
    "    \n",
    "    #drops all hours without data\n",
    "    all_data = all_data.dropna(axis = 0)\n",
    "    \n",
    "    #Shows how many hour chunks are being compared, useful for seeing how much data is being processed.\n",
    "    print('comparing ', len(all_data), ' hours')\n",
    "    \n",
    "    all_data.rename(columns = {'PM1.0_CF1_ug/m3':'PM1p', \n",
    "                                'PM2.5_ATM_ug/m3':'PM25p', \n",
    "                                'PM10.0_CF1_ug/m3':'PM10p'}, inplace = True)\n",
    "    \n",
    "    all_data.rename(columns = {'PM1':'PM1d', \n",
    "                                'PM25':'PM25d', \n",
    "                                'PM10':'PM10d'}, inplace = True)\n",
    "    return all_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(location_name):\n",
    "    '''Gets the csv location data from radwatch downloads. '''\n",
    "    \n",
    "    url = 'https://radwatch.berkeley.edu/test/dosenet/' + location_name + '.csv'\n",
    "\n",
    "    header = {\n",
    "      \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "      \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    \n",
    "    s=requests.get(url,headers=header).text\n",
    "    dosenet_data = pd.read_csv(io.StringIO(s))\n",
    "    \n",
    "    return dosenet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_data(all_data, pm):\n",
    "\n",
    "    pm_string_d = None\n",
    "    pm_string_p = None\n",
    "    if pm == '1':\n",
    "        pm_string_d = 'PM1d'\n",
    "        pm_string_p = 'PM1p'\n",
    "        print('PM 1:')\n",
    "    elif pm == '25':\n",
    "        pm_string_d = 'PM25d'\n",
    "        pm_string_p = 'PM25p'\n",
    "        print('PM 2.5:')\n",
    "    elif pm == '10':\n",
    "        pm_string_d = 'PM10d'\n",
    "        pm_string_p = 'PM10p'\n",
    "        print('PM 10:')\n",
    "    else:\n",
    "        raise 'something_wrong' from None\n",
    "    \n",
    "    difference_data = report_diff_avg(all_data, pm_string_d, pm_string_p)\n",
    "    \n",
    "    return difference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_length(dataset1, dataset2):\n",
    "    \n",
    "    max1 = max(dataset1)\n",
    "    min1 = min(dataset1)\n",
    "    max2 = max(dataset2)\n",
    "    min2 = min(dataset2)\n",
    "    fmax = None\n",
    "    fmin = None\n",
    "    \n",
    "    if max1 > max2:\n",
    "        if min1 > min2:\n",
    "            fmin = min1\n",
    "            fmax = max2\n",
    "        if min1 < min2:\n",
    "            fmin = min2\n",
    "            fmax = max2\n",
    "        if min1 == min2:\n",
    "            fmin = min1\n",
    "            fmax = max2\n",
    "    if max1 < max2:\n",
    "        if min1 > min2:\n",
    "            fmin = min1\n",
    "            fmax = max1\n",
    "        if min1 < min2:\n",
    "            fmin = min2\n",
    "            fmax = max1\n",
    "        if min1 == min2:\n",
    "            fmin = min2\n",
    "            fmax = max1\n",
    "    if max1 == max2:\n",
    "        if min1 > min2:\n",
    "            fmin = min1\n",
    "            fmax = max1\n",
    "        if min1 < min2:\n",
    "            fmin = min2\n",
    "            fmax = max1\n",
    "        if min1 == min2:\n",
    "            fmin = min1\n",
    "            fmax = max2\n",
    "        \n",
    "    return fmin, fmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_diff_avg(all_data, pm_string_d, pm_string_p):\n",
    "    \n",
    "    difference_data = abs(all_data[pm_string_d] - all_data[pm_string_p])\n",
    "    avg_diff = np.mean(difference_data)\n",
    "    print('Average difference between dosenet and pair data: ', avg_diff)\n",
    "    \n",
    "    return difference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chs_os_aq', 'etch_roof_aq', 'exploratorium_aq', 'hb_os_aq', 'miramonte_os_aq', 'pinewood_os_aq', 'uw_aq']\n",
      "\n",
      "---------------\n",
      "chs_os_aq\n",
      "found  1  files\n",
      "file  1 :\n",
      "comparing  7  hours\n",
      "PM 1:\n",
      "Average difference between dosenet and pair data:  6.414426269412511\n",
      "PM 2.5:\n",
      "Average difference between dosenet and pair data:  7.387457845397199\n",
      "PM 10:\n",
      "Average difference between dosenet and pair data:  9.511469276215308\n",
      "saving as: chs_os_aq_1_daily.csv\n",
      "\n",
      "---------------\n",
      "etch_roof_aq\n",
      "found  2  files\n",
      "file  1 :\n",
      "comparing  141  hours\n",
      "PM 1:\n",
      "Average difference between dosenet and pair data:  1.2491179287936809\n",
      "PM 2.5:\n",
      "Average difference between dosenet and pair data:  1.8599464299664015\n",
      "PM 10:\n",
      "Average difference between dosenet and pair data:  2.1974948163412815\n",
      "saving as: etch_roof_aq_1_daily.csv\n",
      "file  2 :\n",
      "comparing  106  hours\n",
      "PM 1:\n",
      "Average difference between dosenet and pair data:  0.987287322150621\n",
      "PM 2.5:\n",
      "Average difference between dosenet and pair data:  1.7261198422309574\n",
      "PM 10:\n",
      "Average difference between dosenet and pair data:  1.921954924172322\n",
      "saving as: etch_roof_aq_2_daily.csv\n",
      "\n",
      "---------------\n",
      "exploratorium_aq\n",
      "found  2  files\n",
      "file  1 :\n",
      "comparing  67  hours\n",
      "PM 1:\n",
      "Average difference between dosenet and pair data:  0.8281050241068458\n",
      "PM 2.5:\n",
      "Average difference between dosenet and pair data:  1.003651031532945\n",
      "PM 10:\n",
      "Average difference between dosenet and pair data:  1.3204781299621045\n",
      "saving as: exploratorium_aq_1_daily.csv\n",
      "file  2 :\n",
      "comparing  67  hours\n",
      "PM 1:\n",
      "Average difference between dosenet and pair data:  0.7303433754922362\n",
      "PM 2.5:\n",
      "Average difference between dosenet and pair data:  1.0861362068125922\n",
      "PM 10:\n",
      "Average difference between dosenet and pair data:  1.0725252757728614\n",
      "saving as: exploratorium_aq_2_daily.csv\n",
      "\n",
      "---------------\n",
      "hb_os_aq\n",
      "found  1  files\n",
      "file  1 :\n",
      "comparing  46  hours\n",
      "PM 1:\n",
      "Average difference between dosenet and pair data:  3.092538448973627\n",
      "PM 2.5:\n",
      "Average difference between dosenet and pair data:  3.9907299056483683\n",
      "PM 10:\n",
      "Average difference between dosenet and pair data:  3.3986744582443045\n",
      "saving as: hb_os_aq_1_daily.csv\n",
      "\n",
      "---------------\n",
      "miramonte_os_aq\n",
      "found  0  files\n",
      "\n",
      "---------------\n",
      "pinewood_os_aq\n",
      "found  1  files\n",
      "file  1 :\n",
      "comparing  1  hours\n",
      "PM 1:\n",
      "Average difference between dosenet and pair data:  0.8665806451612901\n",
      "PM 2.5:\n",
      "Average difference between dosenet and pair data:  1.7507818740399381\n",
      "PM 10:\n",
      "Average difference between dosenet and pair data:  2.187233486943163\n",
      "saving as: pinewood_os_aq_1_daily.csv\n",
      "\n",
      "---------------\n",
      "uw_aq\n",
      "found  1  files\n",
      "file  1 :\n",
      "comparing  111  hours\n",
      "PM 1:\n",
      "Average difference between dosenet and pair data:  3.1812169365909426\n",
      "PM 2.5:\n",
      "Average difference between dosenet and pair data:  4.5212119362902365\n",
      "PM 10:\n",
      "Average difference between dosenet and pair data:  5.010342949461928\n",
      "saving as: uw_aq_1_daily.csv\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily averages\n",
    "\n",
    "2.5 p, d, diff\n",
    "\n",
    "within 1 mile\n",
    "\n",
    "check etcheverry hall co2 sensor with beacon http://beacon.berkeley.edu/about/\n",
    "how bad is the offset for the data in co2\n",
    "\n",
    "exploratorium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
